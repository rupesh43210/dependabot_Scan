#!/usr/bin/env python3
"""
Vulnerability Scanner - Optimized Version

A professional vulnerability scanner for GitHub Enterprise repositories
that extracts Dependabot security alerts with intelligent CVSS scoring.

Author: GitHub Copilot
Version: 2.0.0
"""

import os
import json
import csv
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import requests
from github import Github
from dotenv import load_dotenv


class VulnerabilityScanner:
    """
    Professional vulnerability scanner for GitHub Enterprise organizations.
    
    Features:
    - Complete Dependabot alert extraction
    - Intelligent CVSS score mapping
    - Comprehensive error handling
    - Rate limiting protection
    - Professional logging
    """
    
    # CVSS score defaults for missing scores
    SEVERITY_CVSS_MAPPING = {
        'critical': 9.0,
        'high': 7.0,
        'medium': 5.0,
        'low': 3.0
    }
    
    def __init__(self, github_token: str, base_url: str = "https://github.boschdevcloud.com"):
        """
        Initialize the vulnerability scanner.
        
        Args:
            github_token: GitHub Enterprise personal access token
            base_url: GitHub Enterprise base URL
        """
        self.base_url = base_url.rstrip('/')
        self.api_base = f"{self.base_url}/api/v3"
        self.github_token = github_token
        
        # Initialize GitHub client
        self.github_client = Github(base_url=f"{self.base_url}/api/v3", login_or_token=github_token)
        
        # Configure session for API calls
        self.session = requests.Session()
        self.session.headers.update({
            'Authorization': f'token {github_token}',
            'Accept': 'application/vnd.github.v3+json',
            'User-Agent': 'Security-Vulnerability-Scanner/2.0'
        })
        
        self.stats = {
            'repositories_scanned': 0,
            'vulnerabilities_found': 0,
            'repositories_with_vulnerabilities': 0,
            'scan_errors': 0
        }
    
    def get_organization_repositories(self, org_name: str) -> List[str]:
        """
        Fetch all repository names from the organization.
        
        Args:
            org_name: Organization name
            
        Returns:
            List of repository names
        """
        print(f"Fetching repositories from {org_name} organization...")
        
        try:
            org = self.github_client.get_organization(org_name)
            repos = []
            page = 1
            
            # Paginate through all repositories
            while True:
                try:
                    repo_page = list(org.get_repos(type='all').get_page(page - 1))
                    if not repo_page:
                        break
                        
                    print(f"  Found {len(repo_page)} repositories on page {page}")
                    repos.extend([repo.name for repo in repo_page])
                    page += 1
                except Exception as e:
                    if page == 1:
                        # If first page fails, try without pagination
                        all_repos = list(org.get_repos(type='all'))
                        repos.extend([repo.name for repo in all_repos])
                        print(f"  Found {len(all_repos)} repositories")
                    break
            
            print(f"Total repositories found: {len(repos)}")
            return repos
            
        except Exception as e:
            print(f"‚ùå Error fetching repositories: {e}")
            return []
    
    def get_repository_vulnerabilities(self, org_name: str, repo_name: str) -> List[Dict]:
        """
        Extract all Dependabot vulnerabilities from a repository.
        
        Args:
            org_name: Organization name
            repo_name: Repository name
            
        Returns:
            List of vulnerability dictionaries
        """
        url = f"{self.api_base}/repos/{org_name}/{repo_name}/dependabot/alerts"
        vulnerabilities = []
        page = 1
        repo_obj = None
        
        while True:
            try:
                response = self.session.get(url, params={'page': page, 'per_page': 100})
                
                if response.status_code == 403:
                    print(f"  No access to Dependabot alerts for {repo_name}")
                    break
                elif response.status_code == 404:
                    # Repository might be archived or private
                    try:
                        repo_obj = self.github_client.get_repo(f"{org_name}/{repo_name}")
                        if repo_obj.archived:
                            print(f"  Skipping archived repository: {repo_name}")
                        break
                    except:
                        break
                elif response.status_code != 200:
                    print(f"  ‚ö†Ô∏è  Error {response.status_code} for {repo_name}")
                    break
                
                alerts = response.json()
                if not alerts:
                    break
                
                # Get repository object for version extraction if not already obtained
                if repo_obj is None:
                    try:
                        repo_obj = self.github_client.get_repo(f"{org_name}/{repo_name}")
                    except Exception as e:
                        print(f"  ‚ö†Ô∏è  Could not access repository {repo_name}: {e}")
                
                # Process each alert
                for alert in alerts:
                    vulnerability = self._process_vulnerability_alert(repo_name, alert)
                    if vulnerability:
                        # Extract current version from manifest file
                        if repo_obj:
                            current_version = self._extract_current_version(
                                repo_obj,
                                vulnerability.get('manifest_path'),
                                vulnerability.get('package_name'),
                                vulnerability.get('package_ecosystem')
                            )
                            vulnerability['current_version'] = current_version
                            
                            # Log version extraction for debugging
                            if current_version in ['File Not Found', 'Access Denied']:
                                print(f"    üìÅ {vulnerability.get('manifest_path')} ‚Üí {current_version}")
                            elif current_version not in ['Not Available', 'Workflow File', 'Non-Standard Manifest']:
                                print(f"    ‚úÖ {vulnerability.get('package_name')}: {current_version}")
                        
                        vulnerabilities.append(vulnerability)
                
                page += 1
                
            except Exception as e:
                print(f"  ‚ùå Error processing {repo_name}: {e}")
                self.stats['scan_errors'] += 1
                break
        
        return vulnerabilities
    
    def _process_vulnerability_alert(self, repo_name: str, alert: Dict) -> Optional[Dict]:
        """
        Process and normalize a Dependabot alert with intelligent CVSS scoring.
        
        Args:
            repo_name: Repository name
            alert: Raw alert data from GitHub API
            
        Returns:
            Processed vulnerability dictionary
        """
        try:
            security_advisory = alert.get('security_advisory', {})
            dependency = alert.get('dependency', {})
            security_vulnerability = alert.get('security_vulnerability', {})
            
            # Extract CVSS score with intelligent fallback
            cvss_score = security_advisory.get('cvss', {}).get('score')
            severity = security_advisory.get('severity', '').lower()
            
            # Apply intelligent CVSS mapping for missing scores
            if cvss_score is None or cvss_score == 0:
                cvss_score = self.SEVERITY_CVSS_MAPPING.get(severity, 0.0)
            
            return {
                # Repository info
                'repository': repo_name,
                'alert_number': alert.get('number'),
                'alert_state': alert.get('state'),
                'alert_url': alert.get('html_url'),
                
                # Detailed timing and status info
                'alert_created_at': alert.get('created_at'),
                'alert_updated_at': alert.get('updated_at'),
                'alert_dismissed_at': alert.get('dismissed_at'),
                'alert_fixed_at': alert.get('fixed_at'),
                'auto_dismissed_at': alert.get('auto_dismissed_at'),
                
                # Dismissal and resolution details
                'alert_dismissed_reason': alert.get('dismissed_reason'),
                'alert_dismissed_comment': alert.get('dismissed_comment'),
                'dismisser_login': alert.get('dismisser', {}).get('login') if alert.get('dismisser') else None,
                'dismisser_type': alert.get('dismisser', {}).get('type') if alert.get('dismisser') else None,
                
                # Resolution tracking
                'resolution_method': self._determine_resolution_method(alert),
                'days_to_resolution': self._calculate_resolution_days(alert),
                'current_status': self._get_detailed_status(alert),
                
                # Security advisory details
                'cve_id': security_advisory.get('cve_id'),
                'ghsa_id': security_advisory.get('ghsa_id'),
                'summary': security_advisory.get('summary'),
                'description': security_advisory.get('description'),
                'severity': security_advisory.get('severity'),
                'cvss_score': cvss_score,
                'cvss_vector': security_advisory.get('cvss', {}).get('vector_string'),
                'cwe_ids': ','.join([cwe.get('cwe_id', '') for cwe in security_advisory.get('cwes', [])]),
                
                # Publication and lifecycle info
                'published_at': security_advisory.get('published_at'),
                'updated_at': security_advisory.get('updated_at'),
                'withdrawn_at': security_advisory.get('withdrawn_at'),
                
                # Dependency details
                'package_ecosystem': dependency.get('package', {}).get('ecosystem'),
                'package_name': dependency.get('package', {}).get('name'),
                'manifest_path': dependency.get('manifest_path'),
                'scope': dependency.get('scope'),
                
                # Vulnerability specifics
                'vulnerable_version_range': security_vulnerability.get('vulnerable_version_range'),
                'first_patched_version': (
                    security_vulnerability.get('first_patched_version', {}).get('identifier')
                    if security_vulnerability.get('first_patched_version') else None
                ),
                
                # Additional metadata
                'alert_created_date': self._format_date(alert.get('created_at')),
                'alert_fixed_date': self._format_date(alert.get('fixed_at')),
                'alert_dismissed_date': self._format_date(alert.get('dismissed_at')),
                'vulnerability_age_days': self._calculate_age_days(alert.get('created_at')),
                
                # Current version from manifest file
                'current_version': 'Not Available',  # Will be populated during processing
            }
            
        except Exception as e:
            print(f"  ‚ö†Ô∏è  Error processing alert: {e}")
            return None
    
    def _extract_current_version(self, repo_obj, manifest_path: str, package_name: str, ecosystem: str) -> str:
        """
        Extract current version of a package from its manifest file.
        
        Args:
            repo_obj: GitHub repository object
            manifest_path: Path to the manifest file (may be URL-style path)
            package_name: Name of the package
            ecosystem: Package ecosystem (npm, pip, maven, etc.)
            
        Returns:
            Current version string or 'Not Available'
        """
        try:
            if not manifest_path or not package_name:
                return 'Not Available'
            
            # Clean up the manifest path - remove URL-style prefixes
            clean_path = manifest_path
            
            # Handle GitLab-style paths: "repo/blob/-/file.json" -> "file.json"
            if '/blob/-/' in clean_path:
                clean_path = clean_path.split('/blob/-/')[-1]
            
            # Handle GitHub-style paths: "repo/blob/main/file.json" -> "file.json" 
            elif '/blob/' in clean_path:
                parts = clean_path.split('/blob/')
                if len(parts) > 1:
                    # Get everything after the branch part
                    branch_and_file = parts[-1]
                    if '/' in branch_and_file:
                        clean_path = '/'.join(branch_and_file.split('/')[1:])
                    else:
                        clean_path = branch_and_file
            
            # Debug logging to see path transformation
            if clean_path != manifest_path:
                print(f"    üîß Path cleaned: {manifest_path} ‚Üí {clean_path}")
            
            # Skip workflow files and other non-manifest files
            if (clean_path.startswith('.github/workflows/') or 
                clean_path.endswith(('.yml', '.yaml')) or
                '/workflows/' in clean_path):
                return 'Workflow File'
            
            # Skip if ecosystem doesn't match expected file types
            expected_files = {
                'npm': ['package.json', 'package-lock.json'],
                'pip': ['requirements.txt', 'requirements.in', 'pyproject.toml', 'setup.py'],
                'maven': ['pom.xml'],
                'rubygems': ['Gemfile', 'Gemfile.lock'],
                'cargo': ['Cargo.toml', 'Cargo.lock'],
                'nuget': ['.csproj', '.fsproj', '.vbproj', 'packages.config']
            }
            
            if ecosystem in expected_files:
                if not any(clean_path.endswith(ext) for ext in expected_files[ecosystem]):
                    return 'Non-Standard Manifest'
            
            # Get the manifest file content from the default branch (where Dependabot scans)
            try:
                content = repo_obj.get_contents(clean_path)
                file_content = content.decoded_content.decode('utf-8')
            except Exception as e:
                if '404' in str(e):
                    return 'File Not Found'
                elif '403' in str(e):
                    return 'Access Denied'
                else:
                    return 'Access Error'
            
            # Parse based on ecosystem and file type
            if ecosystem == 'npm' and (clean_path.endswith('package.json') or clean_path.endswith('package-lock.json')):
                if clean_path.endswith('package.json'):
                    return self._parse_npm_version(file_content, package_name)
                else:
                    return self._parse_npm_lock_version(file_content, package_name)
            elif ecosystem == 'pip' and (clean_path.endswith('requirements.txt') or clean_path.endswith('requirements.in')):
                return self._parse_pip_version(file_content, package_name)
            elif ecosystem == 'maven' and clean_path.endswith('pom.xml'):
                return self._parse_maven_version(file_content, package_name)
            elif ecosystem == 'rubygems' and (clean_path.endswith('Gemfile') or clean_path.endswith('Gemfile.lock')):
                return self._parse_ruby_version(file_content, package_name)
            elif ecosystem == 'cargo' and clean_path.endswith('Cargo.toml'):
                return self._parse_cargo_version(file_content, package_name)
            else:
                # Log what we're trying to parse for debugging
                print(f"    üîç Ecosystem: {ecosystem}, File: {clean_path}")
                return 'Unsupported Format'
                
        except Exception as e:
            # Handle common GitHub API errors more gracefully
            error_msg = str(e)
            if '404' in error_msg:
                return 'File Not Found'
            elif '403' in error_msg:
                return 'Access Denied'
            elif 'rate limit' in error_msg.lower():
                return 'Rate Limited'
            else:
                return 'Parse Error'
    
    def _parse_npm_version(self, content: str, package_name: str) -> str:
        """Parse version from package.json."""
        import json
        try:
            data = json.loads(content)
            dependencies = data.get('dependencies', {})
            dev_dependencies = data.get('devDependencies', {})
            
            if package_name in dependencies:
                return dependencies[package_name].lstrip('^~>=<')
            elif package_name in dev_dependencies:
                return dev_dependencies[package_name].lstrip('^~>=<')
            else:
                return 'Not Found in Dependencies'
        except Exception:
            return 'Parse Error'
    
    def _parse_npm_lock_version(self, content: str, package_name: str) -> str:
        """Parse version from package-lock.json."""
        import json
        try:
            data = json.loads(content)
            
            # Check in packages section (npm v7+)
            packages = data.get('packages', {})
            for path, package_info in packages.items():
                if path.endswith(f'node_modules/{package_name}') or path == f'node_modules/{package_name}':
                    return package_info.get('version', 'Version Not Found')
            
            # Check in dependencies section (npm v6 and earlier)
            dependencies = data.get('dependencies', {})
            if package_name in dependencies:
                return dependencies[package_name].get('version', 'Version Not Found')
            
            return 'Not Found in Lock File'
        except Exception:
            return 'Parse Error'
    
    def _parse_pip_version(self, content: str, package_name: str) -> str:
        """Parse version from requirements.txt."""
        import re
        try:
            # Look for package_name==version or package_name>=version patterns
            pattern = rf'^{re.escape(package_name)}\s*([><=!]+)\s*([0-9.]+.*?)(?:\s|$|#)'
            for line in content.split('\n'):
                line = line.strip()
                if line.startswith(package_name):
                    match = re.match(pattern, line, re.IGNORECASE)
                    if match:
                        return match.group(2)
            return 'Not Found in Requirements'
        except Exception:
            return 'Parse Error'
    
    def _parse_maven_version(self, content: str, package_name: str) -> str:
        """Parse version from pom.xml."""
        import re
        try:
            # Look for dependency with artifact ID matching package name
            artifact_pattern = rf'<artifactId>{re.escape(package_name)}</artifactId>'
            version_pattern = r'<version>(.*?)</version>'
            
            # Find the dependency block
            dependency_blocks = re.findall(r'<dependency>.*?</dependency>', content, re.DOTALL)
            
            for block in dependency_blocks:
                if re.search(artifact_pattern, block):
                    version_match = re.search(version_pattern, block)
                    if version_match:
                        return version_match.group(1)
            
            return 'Not Found in POM'
        except Exception:
            return 'Parse Error'
    
    def _parse_ruby_version(self, content: str, package_name: str) -> str:
        """Parse version from Gemfile or Gemfile.lock."""
        import re
        try:
            # Look for gem 'package_name', 'version' patterns
            pattern = rf"gem\s+['\"]?{re.escape(package_name)}['\"]?\s*,\s*['\"]([^'\"]+)['\"]"
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                return match.group(1).lstrip('~>')
            
            # Also try Gemfile.lock format
            lock_pattern = rf'{re.escape(package_name)}\s+\(([^)]+)\)'
            lock_match = re.search(lock_pattern, content, re.IGNORECASE)
            if lock_match:
                return lock_match.group(1)
                
            return 'Not Found in Gemfile'
        except Exception:
            return 'Parse Error'
    
    def _parse_cargo_version(self, content: str, package_name: str) -> str:
        """Parse version from Cargo.toml."""
        import re
        try:
            # Look for package_name = "version" patterns
            pattern = rf'{re.escape(package_name)}\s*=\s*["\']([^"\']+)["\']'
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                return match.group(1).lstrip('^~>=<')
            
            return 'Not Found in Cargo.toml'
        except Exception:
            return 'Parse Error'

    def _determine_resolution_method(self, alert: Dict) -> str:
        """Determine how the vulnerability was resolved."""
        if alert.get('fixed_at'):
            return 'Fixed'
        elif alert.get('dismissed_at'):
            reason = alert.get('dismissed_reason', '').lower()
            if 'false positive' in reason:
                return 'Dismissed - False Positive'
            elif 'won\'t fix' in reason or 'wont fix' in reason:
                return 'Dismissed - Won\'t Fix'
            elif 'tolerable risk' in reason:
                return 'Dismissed - Tolerable Risk'
            elif 'used in tests' in reason:
                return 'Dismissed - Used in Tests'
            else:
                return f'Dismissed - {reason.title()}'
        elif alert.get('state') == 'open':
            return 'Open'
        else:
            return 'Unknown'
    
    def _calculate_resolution_days(self, alert: Dict) -> Optional[int]:
        """Calculate days from creation to resolution."""
        from datetime import datetime
        
        created_at = alert.get('created_at')
        resolution_date = alert.get('fixed_at') or alert.get('dismissed_at')
        
        if not created_at or not resolution_date:
            return None
        
        try:
            created = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
            resolved = datetime.fromisoformat(resolution_date.replace('Z', '+00:00'))
            return (resolved - created).days
        except:
            return None
    
    def _get_detailed_status(self, alert: Dict) -> str:
        """Get detailed status description."""
        state = alert.get('state', 'unknown').upper()
        
        if state == 'FIXED':
            return 'RESOLVED - Fixed'
        elif state == 'DISMISSED':
            reason = alert.get('dismissed_reason', 'Unknown')
            return f'RESOLVED - Dismissed ({reason})'
        elif state == 'OPEN':
            severity = alert.get('security_advisory', {}).get('severity', 'unknown').upper()
            age_days = self._calculate_age_days(alert.get('created_at'))
            if age_days:
                return f'OPEN - {severity} ({age_days} days old)'
            else:
                return f'OPEN - {severity}'
        else:
            return f'{state}'
    
    def _format_date(self, date_string: Optional[str]) -> Optional[str]:
        """Format ISO date string to readable format."""
        if not date_string:
            return None
        
        try:
            from datetime import datetime
            dt = datetime.fromisoformat(date_string.replace('Z', '+00:00'))
            return dt.strftime('%Y-%m-%d %H:%M:%S UTC')
        except:
            return date_string
    
    def _calculate_age_days(self, created_at: Optional[str]) -> Optional[int]:
        """Calculate age of vulnerability in days."""
        if not created_at:
            return None
        
        try:
            from datetime import datetime
            created = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
            now = datetime.now(created.tzinfo)
            return (now - created).days
        except:
            return None
    
    def scan_organization(self, org_name: str) -> List[Dict]:
        """
        Scan entire organization for vulnerabilities.
        
        Args:
            org_name: Organization name to scan
            
        Returns:
            List of all vulnerabilities found
        """
        print(f"üîç Starting vulnerability scan for {org_name} organization")
        print("=" * 70)
        
        # Get all repositories
        repositories = self.get_organization_repositories(org_name)
        if not repositories:
            print("‚ùå No repositories found or access denied")
            return []
        
        all_vulnerabilities = []
        
        # Scan each repository
        for i, repo_name in enumerate(repositories, 1):
            print(f"[{i}/{len(repositories)}] Processing {repo_name}...")
            self.stats['repositories_scanned'] += 1
            
            vulnerabilities = self.get_repository_vulnerabilities(org_name, repo_name)
            
            if vulnerabilities:
                print(f"  Found {len(vulnerabilities)} Dependabot alerts")
                all_vulnerabilities.extend(vulnerabilities)
                self.stats['repositories_with_vulnerabilities'] += 1
                self.stats['vulnerabilities_found'] += len(vulnerabilities)
            else:
                print(f"  No Dependabot alerts found")
        
        print(f"‚úÖ Vulnerability scan completed: {len(all_vulnerabilities)} vulnerabilities found")
        return all_vulnerabilities
    
    def save_results(self, vulnerabilities: List[Dict], timestamp: str) -> Tuple[str, str]:
        """
        Save scan results to JSON and CSV files.
        
        Args:
            vulnerabilities: List of vulnerability data
            timestamp: Timestamp string for file naming
            
        Returns:
            Tuple of (json_filename, csv_filename)
        """
        # Create filenames
        json_filename = f"temp_vulnerabilities_{timestamp}.json"
        csv_filename = f"temp_vulnerabilities_{timestamp}.csv"
        
        # Save JSON
        with open(json_filename, 'w') as f:
            json.dump(vulnerabilities, f, indent=2, default=str)
        
        # Save CSV
        if vulnerabilities:
            with open(csv_filename, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=vulnerabilities[0].keys())
                writer.writeheader()
                writer.writerows(vulnerabilities)
        
        return json_filename, csv_filename
    
    def print_statistics(self):
        """Print scan statistics."""
        print(f"\nüìä Scan Statistics:")
        print(f"   Repositories scanned: {self.stats['repositories_scanned']}")
        print(f"   Repositories with vulnerabilities: {self.stats['repositories_with_vulnerabilities']}")
        print(f"   Total vulnerabilities found: {self.stats['vulnerabilities_found']}")
        print(f"   Scan errors: {self.stats['scan_errors']}")


def main():
    """Main execution function."""
    # Load environment variables
    load_dotenv()
    
    github_token = os.getenv('GITHUB_TOKEN')
    if not github_token:
        print("‚ùå Error: GITHUB_TOKEN environment variable not set")
        print("Please set your GitHub Enterprise token in the .env file")
        return
    
    # Initialize scanner
    scanner = VulnerabilityScanner(github_token)
    
    # Example usage - replace with your organization
    org_name = os.getenv('GITHUB_ORG', 'your-organization')
    vulnerabilities = scanner.scan_organization(org_name)
    
    if vulnerabilities:
        # Save results
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        json_file, csv_file = scanner.save_results(vulnerabilities, timestamp)
        
        print(f"\nüìÅ Results saved:")
        print(f"   JSON: {json_file}")
        print(f"   CSV: {csv_file}")
    
    # Print statistics
    scanner.print_statistics()


if __name__ == "__main__":
    main()